{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471d07cc",
   "metadata": {},
   "source": [
    "# Fun with JAX\n",
    "\n",
    "#### [John Stachurski](https://johnstachurski.net/) Nov 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96294e93",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8cf6e",
   "metadata": {},
   "source": [
    "JAX is an [open search project]( https://github.com/jax-ml/jax) created by Google Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3666c",
   "metadata": {},
   "source": [
    "The ecosystem is growing rapidly\n",
    "\n",
    "* [Flax](https://flax.readthedocs.io/en/latest/) -- deep learning\n",
    "* [Optax](https://optax.readthedocs.io/en/latest/) -- optimization with or without autodiff\n",
    "* [Optimistix](https://github.com/patrick-kidger/optimistix) -- fixed points, root finding, nonlinear equations, least squares\n",
    "* [Lineax](https://github.com/patrick-kidger/lineax) -- more linear algebra / matrix operations\n",
    "* [Diffrax](https://docs.kidger.site/diffrax/) -- ODEs / PDEs / SDEs\n",
    "* [PyMC](https://www.pymc.io/welcome.html) -- Bayesian estimation and MCMC with JAX compatibility\n",
    "* [JAX SciPy](https://jax.readthedocs.io/en/latest/jax.scipy.html) -- JAX implementation of some SciPy functions\n",
    "* [Interpax](https://interpax.readthedocs.io/en/latest/api.html) -- interpolation\n",
    "* [Awesome JAX](https://github.com/n2cholas/awesome-jax) -- lots more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1c372",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4c04c",
   "metadata": {},
   "source": [
    "We start with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21669982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86679b91",
   "metadata": {},
   "source": [
    "Let's make sure we have a recent version of JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab5524",
   "metadata": {},
   "source": [
    "Let's check our hardware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0077d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lscpu -e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd519417",
   "metadata": {},
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56917f",
   "metadata": {},
   "source": [
    "A common numerical task is to apply a transformation to a set of data points.\n",
    "\n",
    "Our transformation will be the cosine function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f977d5",
   "metadata": {},
   "source": [
    "### With NumPy\n",
    "\n",
    "Here we evaluate the cosine function at 50 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40db8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 50)\n",
    "y = np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c073e",
   "metadata": {},
   "source": [
    "Let's plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878543ef",
   "metadata": {},
   "source": [
    "### With JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceea067",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, 50)\n",
    "y = jnp.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86fe4a",
   "metadata": {},
   "source": [
    "### With NumPy -- timed version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ace22",
   "metadata": {},
   "source": [
    "Let's try some timed versions with a larger array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fe28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time np.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a31598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time np.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0cd58",
   "metadata": {},
   "source": [
    "### With JAX -- timed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc28e9",
   "metadata": {},
   "source": [
    "Let's run the same operation on JAX\n",
    "\n",
    "(The `block_until_ready()` method is explained a bit later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time jnp.cos(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time jnp.cos(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73e6ed",
   "metadata": {},
   "source": [
    "Notice how the timing changes after we change sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0, 10, n + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time jnp.cos(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time jnp.cos(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2e7db",
   "metadata": {},
   "source": [
    "## Evaluating a more complicated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = np.cos(2 * x**2) + np.sqrt(np.abs(x)) + 2 * np.sin(x**4) - 0.1 * x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b67897",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 10, 100)\n",
    "ax.plot(x, f(x))\n",
    "ax.scatter(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03e379",
   "metadata": {},
   "source": [
    "Now let's try with a large array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f61be",
   "metadata": {},
   "source": [
    "### With NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44546c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50_000_000\n",
    "x = np.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d255b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4302fe",
   "metadata": {},
   "source": [
    "### With JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb00caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = jnp.cos(2 * x**2) + jnp.sqrt(jnp.abs(x)) + 2 * jnp.sin(x**4) - x**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19677b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jax = jnp.linspace(0, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f(x_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f(x_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130c6e3",
   "metadata": {},
   "source": [
    "### Compiling the Whole Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_jax = jax.jit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f_jax(x_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f_jax(x_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10389f08",
   "metadata": {},
   "source": [
    "## Nonlinear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9fc7c",
   "metadata": {},
   "source": [
    "In many cases we want to solve a system of nonlinear equations.\n",
    "\n",
    "This section gives an example --- solving for an equilibrium price vector when supply and demand are nonlinear.\n",
    "\n",
    "We start with a simple two good market.\n",
    "\n",
    "Then we shift up to high dimensions.\n",
    "\n",
    "We will see that, in high dimensions, automatic differentiation and the GPU are very helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c95ef",
   "metadata": {},
   "source": [
    "### A Two Goods Market Equilibrium\n",
    "\n",
    "Let’s start by computing the market equilibrium of a two-good problem.\n",
    "\n",
    "Here's the excess demand function\n",
    "\n",
    "$$\n",
    "e(p) = \n",
    "    \\begin{pmatrix}\n",
    "    e_0(p_0, p_1) \\\\\n",
    "    e_1(p_0, p_1)\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "An equilibrium price vector is a $p=(p_0, p_1)$ such that\n",
    "\n",
    "$$\n",
    "e(p) = 0\n",
    "$$\n",
    "\n",
    "The function below calculates the excess demand for given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c7e91",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def e(p, A, b, c):\n",
    "    \"Excess demand is demand - supply at price vector p\"\n",
    "    return np.exp(- A @ p) + c - b * np.sqrt(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0e49d",
   "metadata": {},
   "source": [
    "Our default parameter values will be\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "            0.5 & 0.4 \\\\\n",
    "            0.8 & 0.2\n",
    "        \\end{pmatrix},\n",
    "            \\qquad \n",
    "    b = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            1\n",
    "        \\end{pmatrix}\n",
    "    \\qquad \\text{and} \\qquad\n",
    "    c = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            1\n",
    "        \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae420e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array(((0.5, 0.4),\n",
    "              (0.8, 0.2)))\n",
    "b = np.ones(2)\n",
    "c = np.ones(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b3b95",
   "metadata": {},
   "source": [
    "Next we plot the two functions $ e_0 $ and $ e_1 $ on a grid of $ (p_0, p_1) $ values, using contour surfaces and lines.\n",
    "\n",
    "We will use the following function to build the contour plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54438df5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_excess_demand(ax, good=0, grid_size=100, grid_max=4, surface=True):\n",
    "    p_grid = np.linspace(0, grid_max, grid_size)\n",
    "    z = np.empty((100, 100))\n",
    "\n",
    "    for i, p_1 in enumerate(p_grid):\n",
    "        for j, p_2 in enumerate(p_grid):\n",
    "            z[i, j] = e((p_1, p_2), A, b, c)[good]\n",
    "\n",
    "    if surface:\n",
    "        cs1 = ax.contourf(p_grid, p_grid, z.T, alpha=0.5)\n",
    "        plt.colorbar(cs1, ax=ax, format=\"%.6f\")\n",
    "\n",
    "    ctr1 = ax.contour(p_grid, p_grid, z.T, levels=[0.0])\n",
    "    ax.set_xlabel(\"$p_0$\")\n",
    "    ax.set_ylabel(\"$p_1$\")\n",
    "    ax.set_title(f'Excess Demand for Good {good}')\n",
    "    plt.clabel(ctr1, inline=1, fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d75a26",
   "metadata": {},
   "source": [
    "Here’s our plot of $ e_0 $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633acc2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_excess_demand(ax, good=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720c57d",
   "metadata": {},
   "source": [
    "Here’s our plot of $ e_1 $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b31277",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_excess_demand(ax, good=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f61de5",
   "metadata": {},
   "source": [
    "We see the black contour line of zero, which tells us when $ e_i(p)=0 $.\n",
    "\n",
    "For a price vector $ p $ such that $ e_i(p)=0 $ we know that good $ i $ is in equilibrium (demand equals supply).\n",
    "\n",
    "If these two contour lines cross at some price vector $ p^* $, then $ p^* $ is an equilibrium price vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267baf3c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for good in (0, 1):\n",
    "    plot_excess_demand(ax, good=good, surface=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd76d6c",
   "metadata": {},
   "source": [
    "It seems there is an equilibrium close to $ p = (1.6, 1.5) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac6577",
   "metadata": {},
   "source": [
    "#### Using a Multidimensional Root Finder\n",
    "\n",
    "To solve for $ p^* $ more precisely, we use a zero-finding algorithm from `scipy.optimize`.\n",
    "\n",
    "We supply $ p = (1, 1) $ as our initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4638cb6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "init_p = np.ones(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0111b2",
   "metadata": {},
   "source": [
    "Now we use a standard hybrid algorithm to find the zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9adde",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "solution = scipy.optimize.root(lambda p: e(p, A, b, c), init_p, method='hybr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a6f65",
   "metadata": {},
   "source": [
    "Here’s the resulting value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739967e4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "p = solution.x\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e79b05",
   "metadata": {},
   "source": [
    "This looks close to our guess from observing the figure. We can plug it back into $ e $ to test that $ e(p) \\approx 0 $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa806e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bdb0e",
   "metadata": {},
   "source": [
    "This is indeed a very small error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d1596",
   "metadata": {},
   "source": [
    "#### Adding Gradient Information\n",
    "\n",
    "In many cases, for zero-finding algorithms applied to smooth functions, supplying the [Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) of the function leads to better convergence properties.\n",
    "\n",
    "Here we manually calculate the elements of the Jacobian\n",
    "\n",
    "$$\n",
    "J(p) = \n",
    "    \\begin{pmatrix}\n",
    "        \\frac{\\partial e_0}{\\partial p_0}(p) & \\frac{\\partial e_0}{\\partial p_1}(p) \\\\\n",
    "        \\frac{\\partial e_1}{\\partial p_0}(p) & \\frac{\\partial e_1}{\\partial p_1}(p)\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adc1ed",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def jacobian_e(p, A, b, c):\n",
    "    p_0, p_1 = p\n",
    "    a_00, a_01 = A[0, :]\n",
    "    a_10, a_11 = A[1, :]\n",
    "    j_00 = -a_00 * np.exp(-a_00 * p_0) - (b[0]/2) * p_0**(-1/2)\n",
    "    j_01 = -a_01 * np.exp(-a_01 * p_1)\n",
    "    j_10 = -a_10 * np.exp(-a_10 * p_0)\n",
    "    j_11 = -a_11 * np.exp(-a_11 * p_1) - (b[1]/2) * p_1**(-1/2)\n",
    "    J = [[j_00, j_01],\n",
    "         [j_10, j_11]]\n",
    "    return np.array(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0503ad",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "solution = scipy.optimize.root(lambda p: e(p, A, b, c),\n",
    "                init_p, \n",
    "                jac=lambda p: jacobian_e(p, A, b, c), \n",
    "                method='hybr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e1ebf",
   "metadata": {},
   "source": [
    "Now the solution is even more accurate (although, in this low-dimensional problem, the difference is quite small):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d8a4d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "p = solution.x\n",
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214315e",
   "metadata": {},
   "source": [
    "#### Newton’s Method via JAX\n",
    "\n",
    "We use a multivariate version of Newton’s method to compute the equilibrium price.\n",
    "\n",
    "The rule for updating a guess $ p_n $ of the equilibrium price vector is\n",
    "\n",
    "\n",
    "<a id='equation-multi-newton'></a>\n",
    "$$\n",
    "p_{n+1} = p_n - J_e(p_n)^{-1} e(p_n) \\tag{3.1}\n",
    "$$\n",
    "\n",
    "Here $ J_e(p_n) $ is the Jacobian of $ e $ evaluated at $ p_n $.\n",
    "\n",
    "Iteration starts from initial guess $ p_0 $.\n",
    "\n",
    "Instead of coding the Jacobian by hand, we use automatic differentiation via `jax.jacobian()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7b0b0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def newton(f, x_0, tol=1e-5, max_iter=15):\n",
    "    \"\"\"\n",
    "    A multivariate Newton root-finding routine.\n",
    "\n",
    "    \"\"\"\n",
    "    x = x_0\n",
    "    f_jac = jax.jacobian(f)\n",
    "    @jax.jit\n",
    "    def q(x):\n",
    "        \" Updates the current guess. \"\n",
    "        return x - jnp.linalg.solve(f_jac(x), f(x))\n",
    "    error = tol + 1\n",
    "    n = 0\n",
    "    while error > tol:\n",
    "        n += 1\n",
    "        if(n > max_iter):\n",
    "            raise Exception('Max iteration reached without convergence')\n",
    "        y = q(x)\n",
    "        error = jnp.linalg.norm(x - y)\n",
    "        x = y\n",
    "        print(f'iteration {n}, error = {error}')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16ff9c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def e(p, A, b, c):\n",
    "    return jnp.exp(- A @ p) + c - b * jnp.sqrt(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f97e5f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "p = newton(lambda p: e(p, A, b, c), init_p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4112ca9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.max(jnp.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a0973",
   "metadata": {},
   "source": [
    "### A High-Dimensional Problem\n",
    "\n",
    "Let’s now apply the method just described to investigate a large market with 5,000 goods.\n",
    "\n",
    "We randomly generate the matrix $ A $ and set the parameter vectors $ b, c $ to $ 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69ead5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "dim = 5_000\n",
    "seed = 32\n",
    "\n",
    "# Create a random matrix A and normalize the rows to sum to one\n",
    "key = jax.random.PRNGKey(seed)\n",
    "A = jax.random.uniform(key, (dim, dim))\n",
    "s = jnp.sum(A, axis=0)\n",
    "A = A / s\n",
    "\n",
    "# Set up b and c\n",
    "b = jnp.ones(dim)\n",
    "c = jnp.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e9adb",
   "metadata": {},
   "source": [
    "Here’s our initial condition $ p_0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062a1ea",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "init_p = jnp.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862f0fa",
   "metadata": {},
   "source": [
    "By combining the power of Newton’s method, JAX accelerated linear algebra,\n",
    "automatic differentiation, and a GPU, we obtain a relatively small error for\n",
    "this high-dimensional problem in just a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10359f89",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%time p = newton(lambda p: e(p, A, b, c), init_p).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754dddc4",
   "metadata": {},
   "source": [
    "Here’s the size of the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00776118",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.max(jnp.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd148c81",
   "metadata": {},
   "source": [
    "With the same tolerance, SciPy’s `root` function takes much longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93b3e2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "solution = scipy.optimize.root(lambda p: e(p, A, b, c),\n",
    "                init_p,\n",
    "                method='hybr',\n",
    "                tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089d90c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "p = solution.x\n",
    "jnp.max(jnp.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4bf54",
   "metadata": {},
   "source": [
    "## More Resources\n",
    "\n",
    "* QuantEcon's [JAX lectures](https://jax.quantecon.org/intro.html)\n",
    "* [Deep learning with JAX](https://www.manning.com/books/deep-learning-with-jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacde8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
